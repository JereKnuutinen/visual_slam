{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import os \n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def KeyPoints2CameraCoords(kp, K, w, h):\n",
    "    # Keypoints to homogeneous point coordinates\n",
    "    kp_tf = np.concatenate((kp, np.ones((np.shape(kp)[0],1))), axis=1)\n",
    "    # Keypoints to camera coordinate system\n",
    "    kp_tf = kp_tf @ np.linalg.inv(K.T)\n",
    "    limits = np.squeeze(np.array([w, h, 1]) @ np.linalg.inv(K.T)) # e.g. [1920,1080,1] to camera coords\n",
    "    w_k, h_k = limits[0,0], limits[0,1]\n",
    "    # Define T_norm based on width and height of the image (now in camera coords)\n",
    "    T_norm = np.diag([2/(w_k - 1.), 2/(h_k - 1.), 1]) # normalize\n",
    "    T_norm[:,2] = [-1, -1, 1] # translate\n",
    "    # Conditioning/Normalization of keypoints\n",
    "    kp_tf = kp_tf @ T_norm.T\n",
    "    return kp_tf, T_norm\n",
    "\n",
    "\n",
    "def NormalizeKeypoints(kp, w, h):\n",
    "    # Keypoints to homogeneous point coordinates\n",
    "    kp_tf = np.concatenate((kp, np.ones((np.shape(kp)[0],1))), axis=1)\n",
    "    # Define T_norm based on width and height of the image (now in camera coords)\n",
    "    T_norm = np.diag([2/(w - 1.), 2/(h - 1.), 1]) # normalize\n",
    "    T_norm[:,2] = [-1, -1, 1] # translate\n",
    "    # Conditioning/Normalization of keypoints\n",
    "    kp_tf = kp_tf @ T_norm.T\n",
    "    return kp_tf, T_norm\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "class FeatureExtractor:\n",
    "    def __init__(self):\n",
    "        self.extractor = cv2.SIFT_create()\n",
    "        \n",
    "    def compute_features(self, img):\n",
    "        pts = cv2.goodFeaturesToTrack(np.mean(img, axis=2).astype(np.uint8), 3000, qualityLevel=0.01, minDistance=7)\n",
    "        kps = [cv2.KeyPoint(x=f[0][0], y=f[0][1], size=20) for f in pts]\n",
    "        kp, des = self.extractor.compute(img, kps)\n",
    "        return kp, des\n",
    "        \n",
    "        #kp, des = self.extractor.detectAndCompute(img,None)\n",
    "        #return kp, des\n",
    "\n",
    "\n",
    "class FeatureMatcher:\n",
    "    def __init__(self):\n",
    "        self.matcher = cv2.BFMatcher()\n",
    "    def match_features(self, frame_prev, frame_cur):\n",
    "        kp1, desc1 = frame_prev.keypoints, frame_prev.features\n",
    "        kp2, desc2 = frame_cur.keypoints, frame_cur.features\n",
    "        # Match descriptors.\n",
    "        matches = self.matcher.knnMatch(desc1,desc2,k=1)\n",
    "        # Sort the matches according to nearest neighbor distance ratio (NNDR) (CV course, exercise 4)\n",
    "        distmat = np.dot(desc1, desc2.T)\n",
    "        X_terms = np.expand_dims(np.diag(np.dot(desc1, desc1.T)), axis=1)\n",
    "        X_terms = np.tile(X_terms,(1,desc2.shape[0]))\n",
    "        Y_terms = np.expand_dims(np.diag(np.dot(desc2, desc2.T)), axis=0)\n",
    "        Y_terms = np.tile(Y_terms,(desc1.shape[0],1))\n",
    "        distmat = np.sqrt(Y_terms + X_terms - 2*distmat)\n",
    "        ## We determine the mutually nearest neighbors\n",
    "        dist1 = np.amin(distmat, axis=1)\n",
    "        ids1 = np.argmin(distmat, axis=1)\n",
    "        dist2 = np.amin(distmat, axis=0)\n",
    "        ids2 = np.argmin(distmat, axis=0)\n",
    "        pairs = []\n",
    "        for k in range(ids1.size):\n",
    "            if k == ids2[ids1[k]]:\n",
    "                pairs.append(np.array([k, ids1[k], dist1[k]]))\n",
    "        pairs = np.array(pairs)\n",
    "        # We sort the mutually nearest neighbors based on the nearest neighbor distance ratio\n",
    "        NNDR = []\n",
    "        for k,ids1_k,dist1_k in pairs:\n",
    "            r_k = np.sort(distmat[int(k),:])\n",
    "            nndr = r_k[0]/r_k[1]\n",
    "            NNDR.append(nndr)\n",
    "\n",
    "        id_nnd = np.argsort(NNDR)\n",
    "        return np.array(matches)[id_nnd]\n",
    "\n",
    "class TransformationEstimator:\n",
    "    # Uses ransac algorithm to find best estimation of essential matrix between images\n",
    "    def __init__(self, N=10, Threshold=0.2):\n",
    "        self.N_iterations = N\n",
    "        self.Threshold = Threshold\n",
    "        \n",
    "    def F_from_point_pairs(xs,xss):\n",
    "        # xs, xss: Nx3 homologous point coordinates, N>7\n",
    "        # returns F: 3x3 Fundamental matrix\n",
    "        # Coefficient matrix\n",
    "        N = np.size(xs)[0]\n",
    "        A = np.zeros((N, 9))\n",
    "        for n in range(N):\n",
    "            A[n,:] = np.kron(xss[n,:], xs[n,:])\n",
    "        # Singular-value-decomposition\n",
    "        U,D,V = np.linalg.svd(A, full_matrices=True, compute_uv=True)\n",
    "        Fa = np.reshape(V[:,:,8], (3,3)) # approximation of F, could be > rank 2\n",
    "        Ua,Da,Va = np.linalg.svd(Fa, full_matrices=True, compute_uv=True)\n",
    "        F = (Ua * np.diag([Da[0,0], Da[1,1], 0])) @ Va\n",
    "        return F \n",
    "    \n",
    "    def E_from_point_pairs(xs,xss):\n",
    "        # xs, xss: Nx3 homologous point coordinates, N>7\n",
    "        # returns E: 3x3 Essential matrix\n",
    "        # Coefficient matrix\n",
    "        N = np.size(xs)[0]\n",
    "        A = np.zeros((N, 9))\n",
    "        for n in range(N):\n",
    "            A[n,:] = np.kron(xss[n,:], xs[n,:])\n",
    "        # Singular-value-decomposition\n",
    "        U,D,V = np.linalg.svd(A, full_matrices=True, compute_uv=True)\n",
    "        Ea = np.reshape(V[:,:,8], (3,3)) # approximation of F, could be > rank 2\n",
    "        Ua,Da,Va = np.linalg.svd(Ea, full_matrices=True, compute_uv=True)\n",
    "        E = (Ua * np.diag([1,1,0])) @ Va\n",
    "        return E\n",
    "      \n",
    "    def ransack(self, cur_frame_kp, prev_frame_kp, matches, T_norm, K):\n",
    "        # cur_frame_kp, prev_frame_kp: Nx2 pixel coordinates of keypoints matching between images\n",
    "        # T_norm, 3x3 transformation matrix of keypoints: center of mass to (0,0), x and y to scale [-1,1]\n",
    "        # K: camera calibration matrix\n",
    "        N = np.size(cur_frame_kp)[0]\n",
    "        highest_number_of_inliers = -1\n",
    "        best_essential = np.eye(3)\n",
    "        seed_n = 8 # has to be > 7\n",
    "        # Keypoints to homogeneous point coordinates\n",
    "        kp1 = np.concatenate((prev_frame_kp, np.ones(np.shape(N))))\n",
    "        kp2 = np.concatenate((cur_frame_kp, np.ones(np.shape(N))))\n",
    "        # Keypoints to camera coordinate system\n",
    "        kp1 = kp1 @ K.T\n",
    "        kp2 = kp2 @ K.T\n",
    "        # Conditioning/Normalization of keypoints\n",
    "        kp1 = kp1 @ T_norm.T\n",
    "        kp2 = kp2 @ T_norm.T\n",
    "        # Ransac loop\n",
    "        for n in range(self.N_iterations):\n",
    "            # Randomly select a seed group of > 7 matches\n",
    "            seed_group = np.random.randint(low=0, high=N, size=seed_n)\n",
    "            xs = kp1[seed_group,:]\n",
    "            xss = kp2[seed_group,:]\n",
    "            E = self.E_from_point_pairs(xs, xss)\n",
    "        \n",
    "        return(E)\n",
    "\n",
    "class Frame:\n",
    "    def __init__(self, rgb_fp, d_path, feature_extractor):\n",
    "        self.rgb = cv2.imread(rgb_fp)\n",
    "        self.depth = cv2.imread(d_path)\n",
    "        self.keypoints, self.features  = None, None\n",
    "        self.feature_extractor = feature_extractor\n",
    "    def process_frame(self):\n",
    "        self.keypoints, self.features = self.feature_extract(self.rgb)\n",
    "        return self.keypoints, self.features, self.rgb\n",
    "        \n",
    "    def feature_extract(self, rgb):\n",
    "        return self.feature_extractor.compute_features(rgb)\n",
    "        \n",
    "def compute_fundamental_matrix(kp1, kp2, matches):\n",
    "    \"\"\"\n",
    "    Takes in filenames of two input images \n",
    "    Return Fundamental matrix computes \n",
    "    using 8 point algorithm\n",
    "    \"\"\"\n",
    "    \n",
    "    # extract points\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    for i,(m) in enumerate(matches):\n",
    "        #print(m.distance)\n",
    "        pts2.append(kp2[m[0].trainIdx].pt)\n",
    "        pts1.append(kp1[m[0].queryIdx].pt)\n",
    "    pts1  = np.asarray(pts1)\n",
    "    pts2 = np.asarray(pts2)\n",
    "    \n",
    "    # Compute fundamental matrix\n",
    "    F, mask = cv2.findFundamentalMat(pts1,pts2,cv2.FM_8POINT)\n",
    "    return F \n",
    "\n",
    "def essentialToRt(E):\n",
    "    # see wikipedia: https://en.wikipedia.org/wiki/Essential_matrix\n",
    "    U,d,Vt = np.linalg.svd(E)\n",
    "    W = np.mat([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n",
    "    Winv = W.T\n",
    "    # ansatz (educated guess)\n",
    "    t = U @ W @ np.diag(d) @ U.T\n",
    "    R = U @ Winv @ Vt\n",
    "    return R, t\n",
    "\n",
    "debug = True\n",
    "scale = 5000\n",
    "D = np.array([0, 0, 0, 0], dtype=np.float32)  # no distortion\n",
    "K = np.matrix([[481.20, 0, 319.5], [0, 480.0, 239.5], [0, 0, 1]])  # camera intrinsic parameters\n",
    "fx, fy, cx, cy = 481.20, 480.0, 319.5, 239.5\n",
    "\n",
    "'''\n",
    "\n",
    "def get_color(img, pt):\n",
    "        x = int(np.clip(pt[0], 0, width - 1))\n",
    "        y = int(np.clip(pt[1], 0, height - 1))\n",
    "        color = img[y, x]\n",
    "        if isinstance(color, Number):\n",
    "            color = np.array([color, color, color])\n",
    "        return color[::-1] / 255.\n",
    "\n",
    "def point2dTo3d(n, m, d):\n",
    "    z = float(d) / scale\n",
    "    x = (n - cx) * z / fx\n",
    "    y = (m - cy) * z / fy\n",
    "    point = np.array([x, y, z], dtype=np.float32)\n",
    "    return point\n",
    "\n",
    "\n",
    "def solvePnP(frame1, frame2, matches):\n",
    "        kp1, kp2, des1, des2, depth = frame1.keypoints, frame2.keypoints, frame1.features, frame2.features, frame1.depth\n",
    "        goodMatches = matches\n",
    "    \n",
    "        pts_obj, pts_img2, pts_img1 = [], [], []\n",
    "        colour = []\n",
    "        features = []\n",
    "        for i in range(0, len(goodMatches)):\n",
    "            p = kp1[goodMatches[i][0].queryIdx].pt\n",
    "            # d = depth[int(p[1])][int(p[0])]\n",
    "            d = depth.getpixel((int(p[0]), int(p[1])))\n",
    "            if d == 0:\n",
    "                pass\n",
    "            else:\n",
    "                p2 = kp2[goodMatches[i][0].trainIdx].pt\n",
    "                #dif = abs(cv2.norm(p) - cv2.norm(p2))\n",
    "                #if dif > .1:\n",
    "                    #print('dif -> {}'.format(dif))\n",
    "                    #pass\n",
    "                pts_img2.append(p2)\n",
    "                pts_img1.append(p)\n",
    "                pd = point2dTo3d(p[0], p[1], d)\n",
    "                pts_obj.append(pd)\n",
    "                # c = frame1.rgb[int(p[1])][int(p[0])]\n",
    "                colour.append(get_color(img=frame1.rgb, pt=p))\n",
    "                features.append(des1[goodMatches[i][0].queryIdx])\n",
    "\n",
    "        pts_obj, pts_img2 = np.array(pts_obj), np.array(pts_img2)\n",
    "        pts_img1 = np.array(pts_img1)\n",
    "        if debug:\n",
    "            print('pts_obj -> {}, pts_img->{}'.format(np.shape(pts_obj), np.shape(pts_img2)))\n",
    "        retval, rvec, tvec, inliers = cv2.solvePnPRansac(pts_obj, pts_img2, K, D, useExtrinsicGuess=False)\n",
    "    '''\n",
    "\n",
    "\n",
    "def opencv_R_t(E,kp1, kp2, matches):\n",
    "    \"\"\"\n",
    "    Takes in filenames of two input images \n",
    "    Return Fundamental matrix computes \n",
    "    using 8 point algorithm\n",
    "    \"\"\"\n",
    "    \n",
    "    # extract points\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    for i,(m) in enumerate(matches):\n",
    "        #print(m.distance)\n",
    "        pts2.append(kp2[m[0].trainIdx].pt)\n",
    "        pts1.append(kp1[m[0].queryIdx].pt)\n",
    "    pts1  = np.asarray(pts1)\n",
    "    pts2 = np.asarray(pts2)\n",
    "    \n",
    "    pts_l_norm = cv2.undistortPoints(np.expand_dims(pts1, axis=1), cameraMatrix=K, distCoeffs=None)\n",
    "    pts_r_norm = cv2.undistortPoints(np.expand_dims(pts2, axis=1), cameraMatrix=K, distCoeffs=None)\n",
    "\n",
    "    points, R, t, mask = cv2.recoverPose(E,pts_l_norm, pts_r_norm)\n",
    "    return R,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jerek\\Documents\\Koulu\\Aalto syksy 2022\\visual_slam\\\\data\\ICL_NUIM\\rgb\\\n",
      "[[-9.99779581e-01  1.25375812e-02  1.68403866e-02]\n",
      " [-1.25463071e-02 -9.99921207e-01 -4.12599352e-04]\n",
      " [-1.68338867e-02  6.23793068e-04 -9.99858106e-01]]\n",
      "[[ 5.19144418e-02 -6.26134151e+01  3.37150105e+00]\n",
      " [ 6.21205719e+01 -1.65189214e-01 -1.09700511e+02]\n",
      " [-3.52761128e+00  1.10589183e+02  1.13274773e-01]]\n",
      "[[ 9.99779581e-01 -1.25375812e-02 -1.68403866e-02]\n",
      " [ 1.25463071e-02  9.99921207e-01  4.12599352e-04]\n",
      " [ 1.68338867e-02 -6.23793068e-04  9.99858106e-01]]\n",
      "[[-0.86986325]\n",
      " [-0.02724269]\n",
      " [-0.49254011]]\n"
     ]
    }
   ],
   "source": [
    "# Filepaths\n",
    "import os\n",
    "#cur_dir = os.getcwd()\n",
    "cur_dir = \"c:\\\\Users\\\\jerek\\\\Documents\\\\Koulu\\\\Aalto syksy 2022\\\\visual_slam\\\\\"\n",
    "dir_rgb = cur_dir + \"/data/ICL_NUIM/rgb/\"\n",
    "dir_depth = cur_dir + \"/data/ICL_NUIM/depth/\"\n",
    "is_WINDOWS = True\n",
    "if is_WINDOWS:\n",
    "    dir_rgb = dir_rgb.replace(\"/\", \"\\\\\")\n",
    "    dir_depth = dir_depth.replace(\"/\", \"\\\\\")\n",
    "# Initialize\n",
    "print(dir_rgb)\n",
    "feature_extractor = FeatureExtractor()\n",
    "feature_matcher = FeatureMatcher()\n",
    "\n",
    "\n",
    "# run feature extraction for 1st image\n",
    "fp_rgb = dir_rgb + str(1) + \".png\"\n",
    "#print(fp_rgb)\n",
    "im = cv2.imread(fp_rgb)\n",
    "#print(im)\n",
    "fp_depth = dir_depth + str(1) + \".png\"\n",
    "cur_frame = Frame(fp_rgb, fp_depth, feature_extractor)\n",
    "kp1, features1, rgb1 = cur_frame.process_frame() \n",
    "\n",
    "prev_frame = cur_frame\n",
    "i = 30 # jump to 30th frame\n",
    "\n",
    "fp_rgb = dir_rgb + str(i) + \".png\"\n",
    "fp_depth = dir_depth + str(i) + \".png\"\n",
    "# Feature Extraction for current frame\n",
    "cur_frame = Frame(fp_rgb, fp_depth, feature_extractor)\n",
    "kp2, features2, rgb2 = cur_frame.process_frame()\n",
    "\n",
    "# Feature Matching to previous frame\n",
    "matches = feature_matcher.match_features(prev_frame, cur_frame) \n",
    "\n",
    "best8 = matches[:8]\n",
    "\n",
    "F = compute_fundamental_matrix(kp1, kp2, matches[:100])\n",
    "F\n",
    "#img3 = cv2.drawMatchesKnn(prev_frame.rgb,prev_frame.keypoints, cur_frame.rgb,cur_frame.keypoints,matches[:8],None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "#img2 = cv2.drawKeypoints(rgb, kp, None, color=(0,255,0), flags=0)\n",
    "#cv2.imshow('a', img3)\n",
    "#cv2.waitKey(0)\n",
    "E = K.T @ F @ K\n",
    "#print(E)\n",
    "\n",
    "R, t = essentialToRt(E)\n",
    "print(R)\n",
    "print(t)\n",
    "\n",
    "# E = U@np.diag(S)@VT\n",
    "R, t = opencv_R_t(E,kp1, kp2,matches[:100])\n",
    "print(R)\n",
    "print(t)\n",
    "\n",
    "#solvePnP()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999989089053"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = np.array([[-0.86986325], [-0.02724269],[-0.49254011]])\n",
    "vec\n",
    "np.linalg.norm(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.array(kp1))\n",
    "\n",
    "# extract points\n",
    "pts1 = []\n",
    "pts2 = []\n",
    "for i,(m) in enumerate(matches):\n",
    "    #print(m.distance)\n",
    "    pts2.append(kp2[m[0].trainIdx])\n",
    "    pts1.append(kp1[m[0].queryIdx])\n",
    "\n",
    "pts1  = np.asarray(pts1)\n",
    "pts2 = np.asarray(pts2)\n",
    "\n",
    "\n",
    "F, mask = cv2.findFundamentalMat(pts1[:100], pts2[:100], cv2.FM_8POINT)\n",
    "print(\"x2.T @ F @ x1 = (should be close to 0)\" )\n",
    "\n",
    "\n",
    "test_idx = 20\n",
    "\n",
    "x1 = np.expand_dims(pts1[test_idx,:], axis=1)\n",
    "x2 = np.expand_dims(pts2[test_idx,:], axis=1)\n",
    "\n",
    "\n",
    "#print(np.shape(x2))\n",
    "\n",
    "\n",
    "\n",
    "print(x2.T @ F @ x1)\n",
    "\n",
    "E = K.T @ F @ K # Get the essential matrix\n",
    "\n",
    "[U,S,V] = np.linalg.svd(E)\n",
    "\n",
    "diag_110 = np.array([[1, 0, 0],[0, 1, 0],[0, 0, 0]])\n",
    "newE = U@diag_110@V\n",
    "[U,S,V] = np.linalg.svd(newE); # Perform second decompose to get S=diag(1,1,0)\n",
    "\n",
    "W = np.array([[0, -1, 0],[1, 0, 0],[0, 0, 1]]) # [0 -1 0; 1 0 0; 0 0 1];\n",
    "\n",
    "R1 = U@W@V\n",
    "R2 = U@W.T@V\n",
    "t1 = U[:,2] #norm = 1\n",
    "t2 = -U[:,2] #norm = 1\n",
    "\n",
    "\n",
    "#print(R1, t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_norm = np.diag([2/(1920 - 1.), 2/(1080 - 1.), 1]) # normalize\n",
    "T_norm[:,2] = [-1, -1, 1] # translate\n",
    "\n",
    "a = np.array([1920,1080,1]) @ np.linalg.inv(K.T)\n",
    "\n",
    "np.shape(np.squeeze(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([m[0].queryIdx for m in best8])\n",
    "[m[0].trainIdx for m in best8]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f90680ee5ab3bcf42cb50e9f636532c015f333683033b39df2cfc69126a0ddc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
